# -*- coding: utf-8 -*-
"""a3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JLdg589NL7ueUb1lg_n_1Z6QxEjCKWmX

Perform the following operations on iris dataset.
1. Display mean, median, minimum, maximum, standard deviation.
2. Provide mean, median, minimum, maximum, standard deviation for a given dataset by grouping using one of the qualitative (categorical) variable.
3. Display missing values and inconsistencies.
4. Replace missing values using any 2 suitable.
"""

#import the required libraries
import numpy as np
import pandas as pd

#read csv file
df = pd.read_csv("Iris.csv")
df

"""1. Display mean, median, minimum, maximum, standard deviation."""

df.describe()

df.info()

"""2. Provide mean, median, minimum, maximum, standard deviation for a given dataset by grouping using one of the qualitative (categorical) variable."""

#It allows you to select columns from a DataFrame based on their data types.
#object: Generic data type often used for columns in pandas DataFrames containing strings, mixed types, or other Python objects.
df.select_dtypes(include='object')

#data = df.groupby(["Species"])
#data.groups.keys()
#df.groupby(['Species']): This groups the DataFrame df by the 'Species' column.
#.groups: This attribute of the groupby object returns a dictionary where the keys are the unique values of the column used for grouping.
#.keys(): This method is used to extract the keys from the dictionary returned by .groups.
df.groupby(['Species']).groups.keys()

df.groupby(["Species"])["SepalLengthCm"].mean()

df.groupby(["Species"])["SepalLengthCm"].median()

df.groupby(["Species"])["SepalLengthCm"].max()

df.groupby(["Species"])["SepalLengthCm"].min()

df.groupby(["Species"])["SepalLengthCm"].var()

df.groupby(["Species"])["SepalLengthCm"].std()

# Grouping the DataFrame by "Species" column
grouped_data = df.groupby("Species")

# Computing aggregate statistics for each group
grouped_data.agg(["sum", "mean", "max",'min',"std"])

# Grouping the DataFrame by "Species" column
grouped_data = df.groupby(["Species"])["SepalLengthCm"]

# Computing aggregate statistics for each group
grouped_data.agg(["sum", "mean","median", "max",'min','var',"std"])

import statistics as stat
df.groupby(["Species"])["SepalLengthCm"].apply(stat.mode)

data = df.groupby("Species")["SepalLengthCm"]

# Define custom functions to apply for aggregation
def custom_agg(data):
    return {
        "sum": sum(data),
        "mean": stat.mean(data),
        "median": stat.median(data),
        "max": max(data),
        "min": min(data),
        "variance": stat.variance(data),
        "standard_deviation": stat.stdev(data)
    }

# Computing aggregate statistics for each group
aggregate_stat = data.agg(custom_agg)
print(aggregate_stat)

"""3. Display missing values and inconsistencies."""

df.isnull()

df.isnull().sum()

#Select Rows with NaN Values in Any Column
df[df.isnull().any(axis=1)]

"""4. Replace missing values using any 2 suitable."""

#The fillna() method replaces the NULL values with a specified value (here replace with 0 (zero)).
df['SepalLengthCm'].fillna(0, inplace=True)
df

#The mode() method returns the mode value of each column.
#The fillna() method replaces the NULL values with a specified value (here replace with node).
pf=df['SepalWidthCm'].mode()
df['SepalWidthCm'].fillna(pf, inplace=True)
df

#The fillna() method replaces the NULL values with a specified value (here replace with 'Missing').
df['PetalLengthCm'].fillna('Missing', inplace=True)
df

#The dropna() method removes the rows that contains NULL values.
df=df.dropna()
df

# Interpolate missing values
# Interpolation is another method for filling missing values based on the values of neighboring data points.
df.interpolate(inplace=True)
df

#Forward fill involves filling missing values with the last known value in the column.
df.ffill(inplace=True)
df
#Backward fill involves filling missing values with the next known value in the column.
df.bfill(inplace=True)
df

