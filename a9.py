# -*- coding: utf-8 -*-
"""a9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bRLBvEdFWBFyHsr3C3igPFnrNBkroEml

For given text apply following preprocessing methods:
1. Tokenization
2. POS Tagging
3. Stop word Removal
4. Lemmatization
5. Stemming
"""

import nltk
nltk.download('wordnet')

"""1. Tokenization"""

from nltk.tokenize import word_tokenize

# Sample text
text = "Text tokenization serves as the initial phase of natural languages processing. It involves segmenting a given text into individual units, like words or sentences, which are known as tokens."

# Tokenization
tokens = word_tokenize(text)
print("Tokenization:", tokens)

"""2. POS Tagging"""

from nltk import pos_tag

# POS Tagging
pos_tags = pos_tag(tokens)
print("POS Tagging:", pos_tags)

"""3. Stop word Removal"""

from nltk.corpus import stopwords

stop_words = set(stopwords.words('english'))

print("stop_words: ",stop_words)
filtered_tokens = [word for word in tokens if word.lower() not in stop_words]
print("Stop word Removal:", filtered_tokens)

"""4. Lemmatization"""

from nltk.stem import WordNetLemmatizer

lemmatizer = WordNetLemmatizer()
lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]
print("Lemmatization:", lemmatized_tokens)

"""5. Stemming"""

from nltk.stem import PorterStemmer

stemmer = PorterStemmer()
stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]
print("Stemming:", stemmed_tokens)

"""
1. **Tokenization**:
   - Tokenization is the process of breaking down a text into smaller units called tokens. These tokens can be words, phrases, or other meaningful elements.
   - For example, consider the sentence: "The quick brown fox jumps over the lazy dog." Tokenization would split this sentence into individual words: ["The", "quick", "brown", "fox", "jumps", "over", "the", "lazy", "dog", "."].
   - Tokenization is a crucial step in natural language processing (NLP) tasks as it helps in extracting meaningful information from text data.

2. **POS Tagging** (Part-of-Speech Tagging):
   - POS tagging is the process of assigning a part-of-speech tag (such as noun, verb, adjective, etc.) to each word in a sentence.
   - This helps in understanding the grammatical structure of a sentence and aids in various NLP tasks such as named entity recognition, text summarization, etc.
   - For example, consider the sentence: "The quick brown fox jumps over the lazy dog." POS tagging would assign tags to each word: [("The", "DT"), ("quick", "JJ"), ("brown", "JJ"), ("fox", "NN"), ("jumps", "VBZ"), ("over", "IN"), ("the", "DT"), ("lazy", "JJ"), ("dog", "NN"), (".", ".")].
   - Here, "DT" represents determiner, "JJ" represents adjective, "NN" represents noun, "VBZ" represents verb (3rd person singular present), and "IN" represents preposition or conjunction.

3. **Stop Word Removal**:
   - Stop words are common words that are often considered irrelevant for text analysis as they do not carry much meaning (e.g., "the", "is", "are", "and", "but", etc.).
   - Stop word removal is the process of filtering out these stop words from text data.
   - This helps in reducing noise in the data and improving the efficiency of text processing algorithms.
   - For example, consider the sentence: "The quick brown fox jumps over the lazy dog." After stop word removal, it would become: ["quick", "brown", "fox", "jumps", "lazy", "dog"].

4. **Lemmatization**:
   - Lemmatization is the process of reducing words to their base or dictionary form (known as lemma) while still ensuring that the reduced form belongs to the language.
   - It involves removing inflections and variations to bring words to their root form.
   - For example, the lemma of the words "running", "ran", and "runs" is "run".
   - Lemmatization helps in standardizing words so that variations of the same word are treated as the same entity in text analysis.

5. **Stemming**:
   - Stemming is similar to lemmatization, but it is a more crude and rule-based approach.
   - It involves removing prefixes and suffixes from words to reduce them to their root or stem form.
   - Stemming is more aggressive than lemmatization and may not always result in valid words.
   - For example, stemming the words "running", "ran", and "runs" would result in "run".
   - Stemming is computationally less expensive compared to lemmatization and is often used in information retrieval systems and text mining tasks."""